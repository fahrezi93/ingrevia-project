import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models, regularizers, Sequential
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Load dataset
recipes_df = pd.read_csv("full_format_recipes.csv")
bert_embeddings = np.load("sbert_embeddings.npy")
scaler = StandardScaler()
normalized_embeddings = scaler.fit_transform(bert_embeddings)
input_dim = bert_embeddings.shape[1]  

class CustomAutoencoder(tf.keras.Model):
    def __init__(self, input_dim, latent_dim=512, **kwargs):
        super(CustomAutoencoder, self).__init__(**kwargs)
        self.input_dim = input_dim
        self.latent_dim = latent_dim

        # Encoder
        self.input_noise = layers.GaussianNoise(0.05)
        self.encoder_dense1 = layers.Dense(
            latent_dim, activation='relu', 
            kernel_regularizer=regularizers.l2(1e-4)
        )
        self.encoder_dense2 = layers.Dense(
            256, activation='relu', 
            kernel_regularizer=regularizers.l2(1e-4)
        )
        self.encoder_latent = layers.Dense(
            latent_dim, activation='relu', 
            kernel_regularizer=regularizers.l1(1e-5)
        )
        self.latent_noise = layers.GaussianNoise(0.05)
        self.latent_normalization = layers.LayerNormalization()

        # Decoder
        self.decoder_dense1 = layers.Dense(
            256, activation='relu', 
            kernel_regularizer=regularizers.l2(1e-4)
        )
        self.decoder_dense2 = layers.Dense(
            512, activation='relu', 
            kernel_regularizer=regularizers.l2(1e-4)
        )
        self.decoder_output = layers.Dense(input_dim, activation='sigmoid')

    def call(self, inputs, training=False):
        # Encoder
        x = self.input_noise(inputs, training=training)
        x = self.encoder_dense1(x)
        skip = x
        x = self.encoder_dense2(x)
        latent = self.encoder_latent(x)
        latent = self.latent_noise(latent, training=training)
        latent = self.latent_normalization(latent)
        latent = layers.add([latent, skip])

        # Decoder
        x = self.decoder_dense1(latent)
        x = self.decoder_dense2(x)
        reconstruction = self.decoder_output(x)
        return reconstruction, latent

    def get_config(self):
        config = super(CustomAutoencoder, self).get_config()
        config.update({
            'input_dim': self.input_dim,
            'latent_dim': self.latent_dim,
        })
        return config

    @classmethod
    def from_config(cls, config):
        return cls(**config)
